---
title: "General Idea of Machine Learning"
draft: false
freeze: true
---

Deep learning is a powerful and popular branch of machine learning that uses neural networks to learn from data and perform complex tasks. Deep learning, as previously illustrated, is a part of machine learning that leverages multiple layers of representations of data for making predictions on a given input data. Therefore, there are some concepts that are also applied when someone want to use deep learning models. This chapter describes the different types of machine learning problems and the sequences on how to solve the problems. Some limitations of machine learning as well as deep learning methods are also discussed.

## Machine Learning Problems

For developers, data scientists, or researchers, machine learning techniques offer them with the capability to handle complex problems by training a mathematical model that can extract some rules or patterns within a sample and use those to generate some predictions. This usually goes beyond the traditional statistical methods that was invented to deal with a smaller amount of data. The main goal here is to achieve the optimal result when the model is deployed in real-world situation, i.e., the model has to be able to predict samples that are not used for the training process. It is important to understand different approaches in machine learning problems.

Machine Learning problems can generally be classified into three, namely supervised learning, unsupervised learning, and reinforcement learning.

- In a **supervised learning**, the model usually is given a dataset containing sets of feature data and its label. The system is trained in order to learn a mapping rules of the inputs to the respective outputs so that it can infer the label of a new, previously-unseen observations. 
- In **unsupervised learning**, the model processes raw data that is neither labeled nor tagged by human. The purpose of this type of problem is to find hidden patterns or structure in the data. 
- In **reinforcement learning**, the model is trained to be the brain of an independent agent which interact with certain environment by performing some actions, observing the impacts of its actions in the environment, and receiving reward or penalties based on its actions. 


One thing to note is that sometimes the lines between these types of problem can be blurry. For example, one can deal with data that is half unlabeled and half labeled in a semi-supervised learning which is a mixture of both supervised and unsupervised learning.

This book discusses several use cases of deep learning in different applications, including in natural language processing, computer vision, and time series analysis. However, each use case is supervised learning where the model is trained using labeled input data and used to predict new dataset. Specifically, all techniques learned in this book is used for either regression or classification problems. **Regression** is a type of problem where the model needs to predict continuous, numerical data whereas, for **classification** problem, the model has to infer categorical label of the data.


## The Workflow    

The workflow when using deep learning is iterative and dynamic that requires a lot of experimentation and creativity. In this book, there is a certain workflow used to train and evaluate a deep learning model. The general steps are also used in building other traditional machine learning models. The workflow has seven primary components.

1. **Acquiring data**: Either collecting by yourself or using existing data, you needs relevant data to solve your business problems. This is typically one of the most important and prone-to-error step in a project. In this book, all data are acquired using publicly available datasets.
2. **Preprocessing**: This step involves cleaning, transforming and organizing your data to make it suitable for your model. More in-depth methods in preprocessing different data types are demonstrated in the Part 3 of this book.
3. **Splitting and balancing the dataset**: Depending on how you approach a problem, in many occasions you might want to separate a subset of available data to function as the test set. Test dataset is a subset used for evaluating the performance of a trained model. Another important subset is the validation set which is used, for instance, to tune hyperparameters or to observere the performance of a model throughout the training process.
4. **Defining model architecture**: For deep learning model, defining model might be arbitrary, but this process can influence the results of the project. In many times, one needs to redefine the architecture iteratively by altering the structure and layers of the neural network in order to achieve the highest performance.
5. **Fitting model to data**: This step involves training your model on the training set. You need to specify a loss function that measures how well your model fits the data and select the optimizer that will determines how the model's parameters are adjusted. In addition, you may want to use particular metrics to evaluate the model performance on the validation set.
6. **Making predictions**: This is the step when you use your trained model to make predictions on new or unseen data. In this step, developers typically measure how well the model performs on the test set using some metrics such as mean squeared error, accuracy, F1-score, and ROC curve.
7. **Model optimization**: This is intended to improve the model by fine-tuning the hyperparameters, adding regularization techniques such as dropout or batch normalization. 


## The Limitations of the Techniques

Machine learning is proven to help many organisations from different industries make better decisions based on insights from data such as the cases in detecting frauds in financial transactions or predicting cancer from medical x-rays. However, it is not a one-for-all solution as there are use cases when using machine learning will not help achieve the best result or is a waste of time. Careful consideration is taken place before actually applying the technique to the problem. 

It is important for individuals or institutions to understand the limitations of the technique to decide whether it is the most appropriate approach. Some of the limitations of Machine learning include:

* It usually needs a significant amount of data in order to learn effectively, especially if you want to train a deep learning model.
* The performance of a model heavily depends on the data it is trained, meaning potential bias might be hard to detect. Overfitting is a common pitfall in machine learning where the model is to specialised in the training data and performs unreliably on test dataset.
* As some techniques of machine learning, including the artificial neural network, is a black box system, the underlying insights behind the trained model can be hard, or even impossible, to understand. This is also a reason why some techniques are specifically designed for predictions, while others are used for inference.