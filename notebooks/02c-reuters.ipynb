{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reuters\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models, layers, optimizers, backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "num_words = 10000\n",
    "\n",
    "(train_data, train_labels,), (test_data, test_labels) = reuters.load_data(num_words = num_words)\n",
    "\n",
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 300 # the avg is 145.54\n",
    "\n",
    "X_train = [seq[:seq_len] for seq in train_data]\n",
    "X_train = [np.append([0] * (seq_len - len(seq)), seq) for seq in X_train]\n",
    "X_train = np.array(X_train).astype(int)\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "\n",
    "X_test = [seq[:seq_len] for seq in test_data]\n",
    "X_test = [np.append([0] * (seq_len - len(seq)), seq) for seq in X_test]\n",
    "X_test = np.array(X_test).astype(int)\n",
    "\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_X_train = X_train[:4500]\n",
    "partial_y_train = y_train[:4500]\n",
    "X_val = X_train[4500:]\n",
    "y_val = y_train[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(X_train, \n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            embedding_dim,\n",
    "            learning_rate,\n",
    "            momentum):\n",
    "    \n",
    "    # define ann architecture\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(num_words, embedding_dim, input_length = seq_len))\n",
    "    model.add(layers.Dense(64, activation = \"relu\"))\n",
    "    model.add(layers.Dense(46, activation = \"sigmoid\"))\n",
    "\n",
    "    # define optimizer, loss function, and metrics\n",
    "    optimizer = optimizers.RMSprop(learning_rate = learning_rate, momentum = momentum)\n",
    "\n",
    "    # train ann model\n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    model.fit(X_train, y_train, epochs = 20, batch_size = 64, verbose = 0)\n",
    "\n",
    "    # evaluate ann model\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose = 0)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "learning_rate_list  = np.logspace(-2, -4, 5)\n",
    "momentum_list       = np.linspace(0.1, 0.9, 5)\n",
    "embedding_dim_list  = 2 ** np.arange(3, 7)\n",
    "\n",
    "param_list = []\n",
    "for learning_rate in learning_rate_list:\n",
    "    for momentum in momentum_list:\n",
    "        for embedding_dim in embedding_dim_list:\n",
    "            param_list.append({\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"momentum\": momentum,\n",
    "                \"embedding_dim\": embedding_dim\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for params in param_list:\n",
    "    val_loss, val_acc = explore(\n",
    "        partial_X_train, \n",
    "        partial_y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        embedding_dim = params[\"embedding_dim\"],\n",
    "        learning_rate = params[\"learning_rate\"],\n",
    "        momentum = params[\"momentum\"],\n",
    "    )\n",
    "    \n",
    "    results.append({\"val_loss\": val_loss,\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"params\": params})\n",
    "\n",
    "    backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimal parameters\n",
    "val_accuracies = [result[\"val_acc\"] for result in results]\n",
    "opt_params     = results[np.argmax(val_accuracies)][\"params\"]\n",
    "\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ann architecture\n",
    "model = models.Sequential()\n",
    "for i in range(opt_params[\"n_layers\"]):\n",
    "    model.add(layers.Dense(opt_params[\"n_units\"], activation = opt_params[\"activation\"]))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# define optimizer, loss function, and metrics\n",
    "optimizer = optimizers.RMSprop(learning_rate = opt_params[\"learning_rate\"], \n",
    "                               momentum = opt_params[\"momentum\"])\n",
    "\n",
    "# train ann model\n",
    "model.build(input_shape = (10000,))\n",
    "model.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 20, batch_size = 64, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "blue_dots = 'bo'\n",
    "solid_blue_line = 'b'\n",
    "\n",
    "plt.plot(epochs, loss, solid_blue_line, label = 'Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history['accuracy']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "blue_dots = 'bo'\n",
    "solid_blue_line = 'b'\n",
    "\n",
    "plt.plot(epochs, accuracy, solid_blue_line, label = 'Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1276247cfa5c9ee4636cf367496103f29036e30efa859b5123807facee62d98b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
